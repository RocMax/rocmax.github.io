{"pages":[{"url":"http://blog.game18.net/posts/2015/10/mo-ta-you-xi-shi-xian-si-lu/","text":"发现一款游戏叫《魔塔》，是一个8bit风格的RPG游戏，主人公出生在一个多层迷宫里，各层迷宫之间通过楼梯相连，每层迷宫中有怪物，门，钥匙，血瓶等，不同颜色的门需要对应颜色的钥匙开启，遇到怪物会开启战斗，最终目标是消灭某一层的boss。 从功能点上来看与之前实现的RPG游戏Demo重合度很高。先分析记录一下实现思路,如果以后有时间和兴趣的话考虑自己做一下. 需要重新构架游戏实现机制，肯定不能逐层写代码实现，而应该完成一种读入游戏资源即可进行游戏的框架，之后只要策划将游戏资源导入即可. 目前想到需要实现的东西： 数据信息存放在sqlite中，从读入的ID获得相应数据 地图分层，从tiledmap读入以下信息： 障碍层（墙，火盆，植物等无法穿越）读入后可用来寻路 敌人层，可读入敌人ID npc层，读入npc ID， 物品层，读入物品ID 门，读入门的颜色 传送门，读入传送门ID用来判断传送至哪一层（游戏原型中只有上一层和下一层两种传送门） 点击目标点后寻路，使用A*寻路，如寻路不成功不移动。寻路成功的话开始移动，移动中如果下一格有敌人，门等采取以下策略 遇到敌人：开启对话框，显示敌人一句对话，有是否战斗的按钮 遇到门：检查背包中是否有对应颜色的钥匙，开启提示框，是否使用钥匙开门（原型中有手持宝剑可破坏一部分门，使用炸弹可破坏栅栏，但炸弹有消耗，与钥匙相同。宝剑的耐久可以设置为-1，永久有效） 寻路算法中可以考虑给怪赋一个较高的移动消耗值与lv相关，使得主角最优先选择无障碍道路，被多怪拦住后会选择级别较低的怪突破 游戏原型中战斗界面采取需要玩家干预，根据玩家点击的时机产生miss hit critical的不同攻击，此方式比起自动战斗游戏性更好，且容易实现，不同怪物也能区分难度，值得借鉴，可以学着做一个别的形式. 宝箱，npc，以及其他收集道具的处理以及npc触发任务的处理有待细化.","tags":"Cocos2d-x","title":"魔塔游戏实现思路"},{"url":"http://blog.game18.net/posts/2015/10/cocos2d-xfang-da-jing-xiao-guo/","text":"挖一篇以前写的笔记,如何用Cocos2d-x实现放大镜效果.主要思路是使用图片的一部分创建Sprite,然后setscale,将生成的sprite添加到点击位置.如果原图分辨率不够的话也可以使用另外的大图,截取范围按照两张图的分辨率比值设定.如果对ontouchmoved进行响应,改变截取的位置,生成新的texture,然后使用sprite->settexture即可实现拖动效果.在ontouchended中销毁sprite即可.基本功能实现非常简单,效果如下: 实现起来虽然简单,但是方形的放大框非常不自然.下面我们就在Cocos2d-x中实现圆形外框的放大镜效果.先看代码: Sprite * HelloWorld :: getMaskedSprite ( cocos2d :: Rect rect ){ Sprite * textureSprite = Sprite :: create ( \"bg.png\" , rect ); Sprite * maskSprite = Sprite :: create ( \"mask.png\" ); //创建RenderTexture,尺寸符合mask RenderTexture * rt = RenderTexture :: create ( maskSprite -> getContentSize (). width , maskSprite -> getContentSize (). height ); maskSprite -> setPosition ( maskSprite -> getContentSize (). width / 2 , maskSprite -> getContentSize (). height / 2 ); textureSprite -> setPosition ( textureSprite -> getContentSize (). width / 2 , textureSprite -> getContentSize (). height / 2 ); //对于mask,需要先渲染到RenderTexture上,源因子1,目标因子0 maskSprite -> setBlendFunc ( BlendFunc { GL_ONE , GL_ZERO } ); //对于原图,渲染的时候透明度采用mask的透明度,这样在mask透明的地方原图也透明,实现蒙板效果,目标因子0去掉mask textureSprite -> setBlendFunc ( BlendFunc { GL_DST_ALPHA , GL_ZERO } ); //开始渲染,先是mask,然后原图 rt -> begin (); maskSprite -> visit (); textureSprite -> visit (); rt -> end (); //提取sprite Sprite * final = Sprite :: createWithTexture ( rt -> getSprite () -> getTexture ()); //反转Y轴,纹理创建时Y轴是反的 final -> setFlippedY ( true ); return final ; } mask是一个圆形图片,长这样: 当然,也可以用其他形状的图片生成各种各样的蒙版. RenderTexture ,可以把它想象为一块可以渲染的画布,它不在屏幕显示的范围内.就像一块调色板,我们可以先用颜料在调色板上调出颜色,再去画板上画画. BlendFunc 是颜色混合函数,用于将源图像和目标图像混合在一起,它提供了多种混合方式,详细说明如下: BlendFunc{GL_ONE,GL_ZERO}这一句设定了一个颜色混合的公式:源因子是1,目标因子是0,于是maskSprite原样复制到画布上,而画布上不管之前有什么颜色,都乘以0,屏蔽掉了. BlendFunc{GL_DST_ALPHA,GL_ZERO}这是另一个公式:源因子是使用目标的透明度,目标因子是0,于是textureSprite的透明度先被设置成maskSprite的透明度,maskSprite是一个圆形,周围是透明的,于是textureSprite除中间圆形区域以外的其他区域被透明化,而目标因子是0,屏蔽掉了maskSprite,最后就只显示了textureSprite的中间部分,其实还是个方形区域,但是周围变透明了. 有一个需要注意的地方,如果Sprite使用了create方法(无论是哪种Create)内部都是会retain一次,但是像rt->getSprite()这种就不是,于是这样取回的Sprite会很快被销毁掉,所以采用使用texture再重建一次然后再返回. 效果如下: 代码见 这里 . 其实稍作改动,我们还可以实现更有趣的效果.比如: 怎么样, 无论从哪个方面来看 效果很不错吧? 是不是有些小激动呢?（¯﹃¯）嘿嘿嘿嘿....","tags":"Cocos2d-x","title":"Cocos2d-x放大镜效果"},{"url":"http://blog.game18.net/posts/2015/10/pythonzhua-qu-wang-ye-shu-ju/","text":"稍微花了点时间学习Python,真是一种好用的语言啊.相对于要求严格的C++,Python非常自由、简单、方便.有时候让我有一种\"这么随便会不会出什么问题?\"的感觉.基本上稍微看一下文档我就能上手干活了,做了一个抓取网页数据的小工具.感谢 静觅的博客 详细讲解了Python爬虫,更棒的是有多个实例供参考. 因为上面推荐的博客里讲解已经非常细致,我就直接上代码好了.另外关于html的基本概念可以参考 这里 . 我们今天要爬的网站是这个: 駿河屋 ,一个日本的电商网站,我们希望能把商品信息抓出来供以后使用.IDE方面,我使用的是Anaconda家的Pycharm,另外还附带一个网页版的界面叫IPython Notebook(Jupyter),可以随写随运行,写比较小的脚本时很方便.那么好,上代码: import urllib import urllib2 import re from bs4 import BeautifulSoup class CRAWSURUGA : def __init__ ( self ): self . user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5)' self . headers = { 'User-Agent' : self . user_agent } #商品类别 self . category = '' #名称关键字 self . searchWord = '' #页码 self . pageIndex = 1 #判断是不是最后一页 self . isLastPage = True #最大读取页数 self . maxPageIndex = 5 def getPage ( self ): try : #请求的各项参数 values = {} #物品种类 values [ 'category' ] = self . category #关键字 values [ 'search_word' ] = self . searchWord #页码 values [ 'page' ] = self . pageIndex #不读取图片 values [ 'photo' ] = 'Off' data = urllib . urlencode ( values ) #组合查询url url = 'http://www.suruga-ya.jp/search?' + data #构建请求的request request = urllib2 . Request ( url , headers = self . headers ) #利用urlopen获取页面代码 response = urllib2 . urlopen ( request ) #读取页面内容 pageCode = response . read () #异常处理 except urllib2 . URLError , e : if hasattr ( e , \"reason\" ): print u\"连接失败,错误原因\" , e . reason return None print '已读取第 %d 页' % self . pageIndex #使用BeautifulSoup解析页面 soup = BeautifulSoup ( pageCode , \"lxml\" ) #如果找到有next的链接,说明不是最后一页,否则是最后一页 if soup . find ( \"link\" , rel = \"next\" ): self . isLastPage = False else : print 'last page' self . isLastPage = True return pageCode #取得查询的物品件数 def getItemNum ( self ): #读取网页 pagecode = self . getPage ( self . pageindex ) if not pagecode : print '页面加载失败' return None #利用正则匹配查找'該当件数' pattern = re . compile ( r'該当件数:([\\d,]+?)&' , re . S ) items = re . findall ( pattern , pagecode ) if not items : print '获取物件数失败' return None #去掉数据中的',' itemnum = int ( items [ 0 ] . replace ( ',' , '' )) print itemnum return itemnum #获取页面中的所有商品 def getItems ( self ): #读取页面 pagecode = self . getPage () if not pagecode : print '页面加载失败' return None #使用BeautifulSoup解析页面 soup = BeautifulSoup ( pagecode , \"lxml\" ) #查找页面中所有table标记,每个table标记中存放一个商品 tables = soup . find_all ( 'table' ) for table in tables : if table . has_attr ( 'class' ): #读取商品状态:新品/中古/预约... print table . tr . span . img [ 'alt' ] #读取商品类别 print table . tr . span . contents [ 2 ] . replace ( '[' , '' ) #读取发售日 print table . tr . td . next_sibling . string #读取商品名称 print table . tr . next_sibling . next_sibling . b . string #读取发售公司 pattern = re . compile ( r'\\[.*?\\]' ) match = re . search ( pattern , table . tr . next_sibling . next_sibling . next_sibling . next_sibling . td . string ) if match : print match . group () #读取商品价格 stringprice = '' for string in table . tr . next_sibling . next_sibling . next_sibling . next_sibling . td . next_sibling . next_sibling . strings : stringprice += string #打印完整价格,定价,税后 pattern = re . compile ( u' \\uffe5 ([\\d,]*)' , re . S ) items = re . findall ( pattern , stringprice ) if items : for item in items : #去掉价格中的',' item = item . replace ( ',' , '' ) print item print '==============================' #输入查询条件 def inputFilter ( self ): print '输入商品类别(留空为全商品): \\n ゲーム:2 \\n 映像ソフト:3 \\n 音楽ソフト:4 \\n おもちゃ・ホビー:5 \\n PCソフト:6 \\n 本:7 \\n 電気製品:8 \\n 食品・食玩:9 \\n 雑貨・小物:10 \\n 同人:11' self . category = raw_input () print '输入搜索关键字:' self . searchWord = raw_input () print '输入初始页码(默认为1):' page = raw_input () if page != '' : self . pageIndex = int ( page ) print '输入最大读取页数(默认为5):' maxpage = raw_input () if maxpage != '' : self . maxPageIndex = int ( maxpage ) 整个过程大体上分两步,第一步是读取网页内容,第二步是查找数据.在查找数据的时候使用了两种方法,第一种是正则表达式匹配,第二种是使用BeautifulSoup解析网页. 正则表达式匹配方式很好理解,语法方面要记得东西比较多(参考 这里 ).注意两点: 括号的使用,在正则表达式模板中每个括号代表一个分组,可以从适配模板的文本中\"抠出\"需要的信息,如上面代码中获取物品件数时使用的正则表达式: '該当件数:([\\d,]+?)&' 问号的使用,正则表达式默认是贪婪匹配的,就是会尽可能多的匹配字符.一般我们会使用问号将其改为非贪婪模式.例如比较常见的使用 .*? 来匹配任意字符, .*?a 表示匹配到遇到的第一个字符 a 为止,不加问号的话会一直匹配下去. BeautifulSoup可将页面解析后按照层级结构组成一个对象,访问时可以使用网页标签查找相应的内容,当然也支持正则搜索.另外,BeautifulSoup还提供了对父节点,子节点,兄弟节点等的访问方法,可以较灵活地按照网页结构获取所需内容.在上面代码中查找发售公司和商品价格时都用了兄弟节点的访问方法.对于网页中某些缺乏关键字而难以使用正则匹配的数据,BeautifulSoup的这种结构化访问方式非常好用. 所有功能都写完了,最后把它们调用起来: test = CRAWSURUGA () test . inputFilter () while True : test . getItems () if test . isLastPage : print 'read to last page,stop' break elif test . pageIndex == test . maxPageIndex : print 'read to max pageindex,stop' break else : test . pageIndex += 1 运行一下,输入查询条件: 输入商品类别(留空为全商品): ゲーム:2 映像ソフト:3 音楽ソフト:4 おもちゃ・ホビー:5 PCソフト:6 本:7 電気製品:8 食品・食玩:9 雑貨・小物:10 同人:11 7 输入搜索关键字: ONEPIECE 输入初始页码(默认为1): 输入最大读取页数(默认为5): 输出结果: 已读取第1页 中古 アニメムック [発売日 2014/03/09] ONEPIECE STRONGWORDS 2 [集英社] 821 200 ============================== 中古 アニメムック [発売日 2011/04/20] ONEPIECE STRONGWOR 下 [集英社] 798 200 ============================== 中古 アニメムック . . . 已读取第2页 . . . 已读取第5页 . . . read to max pageindex,stop 中间数据太多就省略掉了,可以看到我们的目标已经达到.因为只是一个简单的测试,仅做了打印输出. 总结: Python爬网页数据真方便!","tags":"Python","title":"Python抓取网页数据"},{"url":"http://blog.game18.net/posts/2015/10/geng-huan-bo-ke-zhu-ti/","text":"刚弄好的博客突然间挂掉了.运行 make html 的时候所有md文件都报 OSError: [Errno 2] No such file or directory. 分明之前还好好的.分析了一下traceback,发现问题出在 extract_toc 插件.在elegant主题作者的 博客 上可以看到左边有一个 Contents 栏,可以在页面中定位文章的条目,从而方便地在内容之间跳转,很好的一个功能.作者的博客中说要使用这个功能的话需要引入 extract_toc 插件. 顺便说一句需要看Pelican的log,使用 pelican -D -s pelicanconf.py content -o output 而不是make html来运行Pelican 在插件列表中添加 extract_toc 后就出现上面的错误,即使把其他插件都删除只剩 extract_toc 还是会报错.看了一下 extract_toc 的 代码 ,发现这么一段: try : from pandoc_reader import PandocReader except ImportError : PandocReader = False 看来这个插件还擅自引用了 pandoc_reader 这个插件.查看其 代码 : proc = subprocess . Popen ( pandoc_cmd , stdin = subprocess . PIPE , stdout = subprocess . PIPE ) 这里运行时报错,在stackoverflow上有很多类似的问题,subprocess.Popen经常会引起 raise child_exception 然后 No such file or directory. 从他们的讨论内容看来似乎是PATH方面的问题. 如果在 extract_toc 中忽略对 pandoc_reader 的检查直接返回False的话是可以避免报错,但是返回给Pelican的toc仍然是None,在Pelican代码中有个检测,toc为None的时候Content不显示,所以添加 extract_toc 也就没有意义了. 我顺着报错的地方看了一些源码,但还是搞不明白原因.elegant这种用户很多的theme按说出了bug应该会有很多人反映,而且据说elegant的作者更新也很勤快.所以我感觉应该是我的配置或者环境有些问题.在 这里 博主也有提到: plugin的执行顺序是随机的（坑爹），所以最好不要有相互依赖的关系 之后有时间继续研究一下这个问题吧.当务之急是让把博客恢复起来.我把官方Git上的所有主题截图都浏览过,喜欢的并不多,有几个虽然看起来很漂亮,但又有点过于文艺范.后来我发现很多博客都在用 pelican-bootstrap3 主题,风格比较简约适合技术博客. 按着readme配置了一下,发现这个主题可配置的地方很多,功能比较完善.我最喜欢的是可定制的顶部banner,用了黑猫的图片加上黑白配色,堪称完美. 于是Bolg满血复活,测试了几次没发现什么bug,暂且先用这个主题好了.以后研究一下自己学着定制主题吧.","tags":"Python","title":"更换博客主题"},{"url":"http://blog.game18.net/posts/2015/10/li-yong-pelicanhe-github-pagesda-zao-ge-xing-hua-bo-ke-er/","text":"在上一篇里我们已经完成了Pelican的安装,生成网站并部署到GitHub Pages上.下面我们就继续完善网站的设置. 1. 更换主题 目前我们的网站使用默认主题,不是很漂亮,功能也单一,我们首先更换主题.运行: git clone --recursive https://github.com/getpelican/pelican-themes.git 会把所有主题下载到本地,注意使用--recursive参数,否则很多链接的主题只能获取到空文件. 下一步安装主题,有两种方法,在上面的git中提到可以在pelicanconf.py配置文件中指定主题存放路径,如下: THEME = \".../Blog/pelican-themes/theme-name\" 我使用了另一种方法,在pelican-themes文件夹下运行: pelican-themes -i .../Blog/pelican-themes/theme-name 这条命令可以把主题安装到 /Library/Python/2.7/site-packages/pelican/themes 下,然后在配置文件中直接指定主题名即可: THEME = \"theme-name\" 重新 make html ,查看一下是不是已经应用了新的主题. 主题虽然改了,但很多功能还没法使用,我们还需要进行很多配置. 2. 安装插件 插件可以扩展Pelican的功能,很多主题也需要依赖插件运行.和主题的安装一样,首先将插件包下载到本地: git clone --recursive https://github.com/getpelican/pelican-plugins 然后在配置文件中设置插件路径和名称列表: PLUGIN_PATHS = [ 'pelican-plugins' ] PLUGINS = [ 'assets' , 'sitemap' , 'gravatar' ] 简单介绍几个正在用的插件: sitemap 生成sitemap.xml,帮助搜索引擎抓取网站内容.除了添加进插件列表意外,还需要添加一些设置: SITEMAP = { \"format\" : \"xml\" , \"priorities\" : { \"articles\" : 0.7 , \"indexes\" : 0.5 , \"pages\" : 0.3 , }, \"changefreqs\" : { \"articles\" : \"monthly\" , \"indexes\" : \"daily\" , \"pages\" : \"monthly\" , } } render_math 让Pelican支持数学公式,由 MathJax 引擎提供支持,公式语法和LaTex相似,尝试一下: $$E = mc&#94;2$$ tag_cloud 提供 标签云 ,除了显示Tags以外,会按文章数目区分显示不同的标签.这个功能原本是集成在Pelican中的,后来被拿出来作为插件,于是一些旧的主题如果不装这个插件的话标签列表无法显示,例如我尝试使用过的 foundation-default-colours ,安装这个插件就可以解决问题. gzip_cache 将页面压缩为gz格式,提高加载速度. 另外,有些主题需要特定插件的支持,例如我现在用的 elegant 需要安装 extract_toc , tipue_search ,总之查看主题和插件的Readme,自己决定安装哪些插件. 3. 修改配置文件 接下来我们要修改Pelican的配置文件 pelicanconf.py ,这里包含非常多的条目,详细的介绍参见 这里 ,我简单介绍其中几项: 日期格式 DEFAULT_LANG = u'zh' DATE_FORMATS = {'zh' : '%Y-%m-%d(%a)'} 默认的日期格式比较适合国外的习惯,上面两句可以把日期格式改为年-月-日(星期)这样比较适合国人习惯的格式. 文件路径 STATIC_PATHS=[\"imgs\",\"extra\"] EXTRA_PATH_METADATA = { 'extra/CNAME': { 'path': 'CNAME' }, 'extra/favicon.ico': { 'path': 'favicon.ico' }, 'extra/robots.txt': { 'path': 'robots.txt' }, } 我在content目录下建了两个目录 imgs 用来存放图片, extra 里存放了 CNAME,favicon.ico,robots.txt 三个文件.上面两句把imgs文件夹和extra里的三个文件原封不动拷贝到output目录下(注意:imgs是文件夹拷贝,另外三个文件直接拷贝).博文中可以直接使用 ![text](/imgs/filename.jpeg) 这样的链接来引用本地图片.另外三个文件作用分别是: CNAME:解析域名用,后面会说到. favicon.ico:让网页标签中显示图标,像这样 robots.txt:告诉搜索引擎爬虫此网站中的哪些内容不应被搜索引擎获取，哪些可以被获取,写法可以参考 这里 . 文件保存配置 一些主题会要求配置特定的项目,elegant主题推荐如下配置: MD_EXTENSIONS = [ 'codehilite(css_class=highlight)' , 'extra' , 'headerid' , 'toc' ] DIRECT_TEMPLATES = (( 'index' , 'tags' , 'categories' , 'archives' , 'search' , '404' )) TAG_SAVE_AS = '' CATEGORY_SAVE_AS = '' AUTHOR_SAVE_AS = '' 参考官方配置文档可以发现有很多 xxxx_SAVE_AS 的配置项,控制各类页面保存方式,可以使用 {slug} 变量用来获取md文件中的Slug字段.Pelican在保存页面的时候会生成一个文件名,文章名是中文如 随笔 的话会生成类似 sui-bi.html 的文件,同时会过滤掉一些不适合放在路径和文件名中的空格和其他符号.于是带来一个问题,在某些主题中如果添加 C++ 标签的话,保存时会忽略 ++ 生成类似于 ~/tags/c.html 的路径,但是在页面链接中点击 C++ 的tag,网页仍会尝试转向 ~/tags/C++.html 页面,于是报错.elegant主题倒没有这个问题,以后自己定制主题的时候要注意这一点. 其他功能配置: 评论:利用Disqus实现评论功能,只需在配置中添加 DISQUS_SITENAME=\"yoursitename\" Google Analytcs:在配置中添加 GOOGLE_ANALYTICS=\"UA-xxxxxx-xxxx\" 友情链接和社交链接:参照 这里 填写配置文件相关项目 4. Tips 删除线 不是MarkDown的标准语法,使用 ~~ 语法不会被转化为删除线效果,这种情况下可直接使用 <s>删除线</s> . 新建md文件时总是需要在开头写meta data,比较繁琐,我写了一个sh脚本来创建新的md文件,代码如下: #!/bin/sh datetime = $( date +%Y-%m-%d \\ %H:%M:%S ) filename = $( date +%Y%m%d_%H_%M_%S ) echo \"Title: \\nDate: ${ datetime } \\nModified: \\nCategory: \\nTags: \\nSlug: \\nAuthors: \\nSummary: \\nStatus: draft\" >../content/ ${ filename } .md 这样可以自动使用当前日期和时间创建新md文件,而且meta data项目已经都添加好.如果觉得打开shell运行脚本比较麻烦,也可以使用Automator打包成可执行文件(OSX系统).另外,虽然利用 publishconf.py 中的设定可以完成GitHub上传,我还是写了一个脚本完成上传工作: #!/bin/sh commitstr = $( date +%Y%m%d_%H_%M_%S ) cd /Users/lipeng/Documents/Blog make html cd /Users/lipeng/Documents/Blog/output git add . git commit -m ${ commitstr } git push origin master 在脚本中使用 date 获取系统时间,可以确保不会重名,而且上传到GitHub中的commit信息也比较容易识别.我把脚本都扔在tools文件夹中. 使用自己的域名 如果觉得GitHub.io域名不够个性的话,也可以把网站挂在自己的域名下.具体做法是: 在网站根目录新建一个 CNAME 文件(文件名大写,无扩展名),文件中填写域名,我的这个文件中写 blog.game18.net ,将这个文件放在 content/extra 下,按照我们在 这里 的设置, CNAME 文件会被自动拷贝至网站根目录. 登陆域名管理页面,在DNS设定中添加一项: 如果需要做TYPE A设置,参考 这里 将网站同步至GitHub,在根目录下看到 CNAME 文件后,检查Settings页面,应该已显示新域名: 等待几分钟DNS设置生效后即可从新域名访问博客,是不是很酷? 到这里,博客的一些基本设置就完成了,Enjoy your own Blog! if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Python","title":"利用Pelican和GitHub Pages打造个性化博客(二)"},{"url":"http://blog.game18.net/posts/2015/10/li-yong-pelicanhe-github-pagesda-zao-ge-xing-hua-bo-ke-yi/","text":"1. 配置GitHbu Pages 在GitHub中新建一个repository,命名为username.github.io,其中username是github的用户名,我建的是rocmax.github.io. 进入后点击右边栏中的Settings,找到GitHub Pages栏,点击Launch automatic page generator按钮,然后点击Continue to layouts,选择一个主题样式,点击Publish page,一个崭新的GitHub Pages页面就出现了,你可以使用username.github.io访问这个新页面,是不是很酷? 网页虽然能访问了,但离想要的博客还很遥远.当然,直接去编辑html文件可以改变网页内容,我们显然不会采用这种笨办法.我们先把自动生成的文件都删除(不熟悉Git命令的话可以在网页上挨个删掉然后commit,git命令下面会涉及到) 2. 安装Pelican 我的系统环境: OSX Python Git 10.11 2.7.10 2.3.8 使用pip安装Pelican和MarkDown pip install pelican pip install markdown 如果安装时报Permission denied,在命令前加sodu,运行时可能需要输入系统密码. 在磁盘上新建一个文件夹用来存放本地文件,比如我的文件夹叫Blog,然后运行: cd Blog pelican-quickstart 如果你跟我的环境一样的话 from six.moves.html_parser import HTMLParser 这句代码会报错,在six.moves里找不到html_parser.看来出了一些问题,处理之前我们先卸载Pelican pip uninstall pelican . 网上有一种处理方法是把这句代码改为 from HTMLParser import HTMLParser 实测可以解决. 我在网上找到另一种解释说是因为six的版本过低导致,使用 pip install -U six 可以fetch到新版本但是安装报错,加sudo都不让装,好像说是因为six这个组件比较核心.我找到的解决方法是到 这里 下载six的whl格式安装文件可以正常安装. 然后重新安装Pelican,在Blog下运行 pelican-quickstart ,它会问一些问题,按自己喜好回答或者在 这里 找答案,系统会按照答案生成一些配置,以后可以改所以怎么填都行,完成后会在目录下生成很多文件. 这就是Blog下的文件列表: 解释一下其中的部分内容(有些文件是后面加入的): content 存放md文件 develop_server.sh 控制本地网页服务器 Makefile 生成网站 output 存放生成的网站,之后这个文件夹会被同步到GitHub pelican-plugins 插件目录 pelican-themes 主题目录 pelicanconf.py 配置文件 publishconf.py 发布配置文件 tools 我自己加的,后面再讲 到这里安装就基本完成了. 3. 开始写博客 编写一个md文件,在最前边需要添加一些信息,下面是一个例子: Title : My super title #文章标题 * Date : 2010 - 12 - 03 10 : 20 #编写时间 * Modified : 2010 - 12 - 05 19 : 30 #修改时间 Category : Python #类别 * Tags : pelican , publishing #标签 * Slug : my - super - post #翻译不能 , 链接地址字符串 , 可以用来处理文章不同语言版本 Authors : Alexis Metaireau , Conan Doyle #作者 Summary : Short version for index and feeds #摘要 Hello world !...... 加*的是必填项 写完后放到content目录下,然后在Blog文件夹下执行 make html 生成网站.可以看到output目录下已经存放了生成好的文件. 然后继续运行 make devserver 开启网页服务,浏览器访问http://localhost:8000 即可看到生成的网页了,而且文件更改后还可以实时重新生成.用完以后记得 make stopserver 关闭服务. 4. 将网站部署到GitHub Pages 最后一步,将生成的网站部署到GitHub Pages,这一步需要使用一些Git命令,不熟悉的话请参考 这里 . 在终端里进入output目录,执行下列命令: git init #创建Git仓库 git add . #将output下的所有文件加入仓库 git remote add origin https://github.com/username/username.github.io #添加远程仓库,可能会要求输入Github用户名和密码 git pull origin master #将远程仓库中的文件获取回本地,之前已经都删除了,不会获取任何文件,不这样的话之后提交会冲突 git commit -m 'first update' #提交一个更改,命名为\"first update\" git push origin master #将本地更改同步到远程仓库的master分支 运行完成的话博客就上传到GitHub了,可以登陆username.github.io看一下,应该跟上一步最后看到的网页一样. 总结 到这里就把使用Pelican+GitHub Pages搭建个人博客的基本流程介绍完了.生成的博客应该类似于这样: 呃....好像也很丑的样子,而且也没啥功能. 下一篇我们继续定制这个博客,让它变得既美观又功能强大.","tags":"Python","title":"利用Pelican和GitHub Pages打造个性化博客(一)"},{"url":"http://blog.game18.net/posts/2015/10/zhu-xin-bo-ke-kai-zhang/","text":"生命在于折腾! 不久前刚刚开始使用 Blogger ,为了替换一直使用的印象笔记.用了一段时间发现还是不爽,Blogger对MarkDown的支持并不是太好,也没什么好用的编辑器去配合,而且我费半天劲定制的Blogger界面丑得要死.终于,我下定决心再折腾一遍,搞一个更好用的博客. 上网搜一搜,什么博客比较高大上呢?知乎马上给你答案: GitHub Pages ,GitHub推出了支持静态网页的功能,就是GitHub Pages,程序员当然要用GitHub才算专业嘛.我们现在有md文件写博客内容,只要能把它们转成网页然后发布到GitHub Pages上就大功告成了.在GitHub Pages页面上推荐了 Jekyll 应该是最有名的静态博客网站转换工具.但Jekyll是基于Ruby的,我不懂也不想学,于是我选择了基于Python的 Pelican 来完成这项工作. 经过三天的研究, 新博客 终于上线了,本篇是随笔所以不写太多技术内容,下一篇详细写搭建流程吧. 最后,感谢神奈提供的域名,让博客的 B格 更加提高了一点(刚明明说用GitHub才叫专业).感谢 Talha Mansoor 开发的 Elegant 主题,试过了n多个主题以后,发现Elegant果然是当之无愧的 best-pelican-theme .我自己也研究了一下Pelican的主题开发,似乎难度并不高,以后有时间自己也弄一套吧.另外,感谢Pelican,感谢Python......","tags":"随笔","title":"祝!新博客开张!"}]}